{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\Anaconda3\\envs\\tf_gpu_1.14\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "C:\\Users\\user\\Anaconda3\\envs\\tf_gpu_1.14\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "C:\\Users\\user\\Anaconda3\\envs\\tf_gpu_1.14\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "C:\\Users\\user\\Anaconda3\\envs\\tf_gpu_1.14\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "C:\\Users\\user\\Anaconda3\\envs\\tf_gpu_1.14\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "C:\\Users\\user\\Anaconda3\\envs\\tf_gpu_1.14\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "C:\\Users\\user\\Anaconda3\\envs\\tf_gpu_1.14\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "C:\\Users\\user\\Anaconda3\\envs\\tf_gpu_1.14\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "C:\\Users\\user\\Anaconda3\\envs\\tf_gpu_1.14\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "C:\\Users\\user\\Anaconda3\\envs\\tf_gpu_1.14\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "C:\\Users\\user\\Anaconda3\\envs\\tf_gpu_1.14\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "C:\\Users\\user\\Anaconda3\\envs\\tf_gpu_1.14\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import time\n",
    "from MMD_metric import _mix_rbf_kernel, mix_rbf_mmd2, _mmd2\n",
    "from CCF import CCF\n",
    "\n",
    "# set the tensorflow verbosity\n",
    "tf.logging.set_verbosity(tf.logging.DEBUG)\n",
    "\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0,1\" "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "index = 'tep11'\n",
    "\n",
    "folder = 'AE_BP_' + index + '_CCF_final_no_ccf/'\n",
    "\n",
    "model_ = 'model_' + index\n",
    "model = model_+'.ckpt' #'model_index_select.ckpt'\n",
    "\n",
    "if not os.path.isdir(folder):\n",
    "    os.mkdir(folder)\n",
    "    \n",
    "saver_path = os.path.join(folder, model)\n",
    "\n",
    "restore_path = os.path.join(folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(200, 52)\n",
      "(200, 52)\n"
     ]
    }
   ],
   "source": [
    "data_index = \"d11_te.dat\"\n",
    "data_test_index = \"d11.dat\"\n",
    "\n",
    "data_folder = \"tennessee-eastman-profBraatz-master/\"\n",
    "data_path = data_folder + data_index\n",
    "data_test_path = data_folder + data_test_index\n",
    "\n",
    "\n",
    "dat = np.genfromtxt(data_path)\n",
    "tep_data = dat[150:450]\n",
    "print(tep_data.shape)\n",
    "\n",
    "\n",
    "dat_test = np.genfromtxt(data_test_path)\n",
    "tep_data_test = dat_test[200:400]\n",
    "print(tep_data_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "tep_data_pd = pd.DataFrame(tep_data)\n",
    "CCFtrain=CCF(tep_data_pd,maxlag=0)\n",
    "CCFtrain.cal()\n",
    "# CCFtrain.show()\n",
    "tep_data_matrix = CCFtrain.get_matrix()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "41\n",
      "0.03092006033182504\n"
     ]
    }
   ],
   "source": [
    "tep_data_matrix = np.array(tep_data_matrix)\n",
    "ccf_value = 0.4\n",
    "\n",
    "temp = 0\n",
    "for i in range(len(tep_data_matrix)):\n",
    "    for j in range(len(tep_data_matrix)):\n",
    "        if tep_data_matrix[i,j] >= ccf_value:\n",
    "            temp = temp + 1\n",
    "dim_ccf = int((temp-52)/2)\n",
    "dim_ccf_ratio = dim_ccf/((51+1)*51/2)\n",
    "\n",
    "print(dim_ccf)\n",
    "print(dim_ccf_ratio)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(200, 52)\n",
      "(200, 52)\n"
     ]
    }
   ],
   "source": [
    "data_mean = np.mean(tep_data,0)   #(72,)\n",
    "data_std = np.std(tep_data,0,ddof=1) \n",
    "\n",
    "tep_data = (tep_data - data_mean)/data_std\n",
    "tep_data_test = (tep_data_test - data_mean)/data_std\n",
    "\n",
    "print(tep_data.shape)\n",
    "print(tep_data_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_window_multiply(time_series, time_step, multiply):\n",
    "    \n",
    "    series_window_multiply = []\n",
    "    L = len(time_series)\n",
    "\n",
    "    start = 0\n",
    "    end = 0\n",
    "    for i in range(L//time_step):\n",
    "        end = end+time_step\n",
    "        dat = time_series[start:end]\n",
    "        for j in range(multiply):\n",
    "            series_window_multiply.append(dat)\n",
    "        start = end\n",
    "    \n",
    "    series_window_multiply = np.array(series_window_multiply)\n",
    "    \n",
    "    return series_window_multiply"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tep_data_win shape: (200, 1, 52)\n"
     ]
    }
   ],
   "source": [
    "nsteps_gan = 1   \n",
    "multiply = 1     \n",
    "\n",
    "tep_data_win = add_window_multiply(tep_data, nsteps_gan, multiply)\n",
    "print(\"tep_data_win shape:\",tep_data_win.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50\n"
     ]
    }
   ],
   "source": [
    "# training parameters\n",
    "batch_size = 10\n",
    "\n",
    "dim_input = tep_data_win.shape[-1] \n",
    "timestep = tep_data_win.shape[1]\n",
    "dim_z = int(dim_input*(1-dim_ccf_ratio))\n",
    "print(dim_z)\n",
    "\n",
    "# variables : input\n",
    "X = tf.placeholder(tf.float32, shape=(None, timestep, dim_input))\n",
    "Z = tf.placeholder(tf.float32, shape=(None, timestep, dim_z))\n",
    "keep_prob_feed = tf.placeholder(tf.float32)\n",
    "global_step = tf.Variable(0, trainable = False)\n",
    "batch_size_feed = tf.placeholder(tf.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bp_encoder(X, keep_prob_feed, batch_size_feed):\n",
    "    \n",
    "    X_in = tf.reshape(X, (batch_size_feed, timestep, dim_input))\n",
    "    \n",
    "    with tf.variable_scope(\"bp_encoder\", reuse = tf.AUTO_REUSE):\n",
    "\n",
    "        hidden = tf.layers.dense(X_in, units = 256, activation=tf.nn.relu)\n",
    "        hidden = tf.layers.dropout(hidden, rate = 1-keep_prob_feed) \n",
    "        \n",
    "        hidden = tf.layers.dense(hidden, units = 512, activation=tf.nn.relu)\n",
    "        hidden = tf.layers.dropout(hidden, rate = 1-keep_prob_feed)\n",
    "        \n",
    "        hidden = tf.layers.dense(hidden, units = 128, activation=tf.nn.relu)\n",
    "        hidden = tf.layers.dropout(hidden, rate = 1-keep_prob_feed) \n",
    "        \n",
    "        hidden = tf.layers.dense(hidden, units = dim_z)\n",
    "        hidden = tf.layers.dropout(hidden, rate = 1-keep_prob_feed)  #(batch_size, timestep, dim_z)\n",
    "\n",
    "        z = tf.reshape(hidden, (batch_size_feed, timestep, dim_z))\n",
    "                \n",
    "    return z\n",
    "\n",
    "def bp_decoder(Z, keep_prob_feed, batch_size_feed):\n",
    "    \n",
    "    Z_in = tf.reshape(Z, (batch_size_feed, timestep, dim_z))\n",
    "\n",
    "    with tf.variable_scope(\"bp_decoder\", reuse = tf.AUTO_REUSE):\n",
    "\n",
    "        hidden = tf.layers.dense(Z_in, units = 128, activation=tf.nn.relu) \n",
    "        hidden = tf.layers.dropout(hidden, rate = 1-keep_prob_feed) \n",
    "        \n",
    "        hidden = tf.layers.dense(hidden, units = 512, activation=tf.nn.relu)\n",
    "        hidden = tf.layers.dropout(hidden, rate = 1-keep_prob_feed)\n",
    "        \n",
    "        hidden = tf.layers.dense(hidden, units = 256, activation=tf.nn.relu)\n",
    "        hidden = tf.layers.dropout(hidden, rate = 1-keep_prob_feed) \n",
    "        \n",
    "        hidden = tf.layers.dense(hidden, units = dim_input)\n",
    "        hidden = tf.layers.dropout(hidden, rate = 1-keep_prob_feed)\n",
    "        \n",
    "        gen_outputs = tf.reshape(hidden, (batch_size_feed, timestep, dim_input))\n",
    "\n",
    "        return gen_outputs\n",
    "    \n",
    "def VAE_BP(X, keep_prob_feed, batch_size_feed):\n",
    "    z = bp_encoder(X, keep_prob_feed, batch_size_feed)\n",
    "    generated_output = bp_decoder(z, keep_prob_feed, batch_size_feed)\n",
    "\n",
    "    return X, z, generated_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def CCF_tf_two(x,y):\n",
    "\n",
    "    x_shape = tf.shape_n([x])\n",
    "    len_x = x_shape[0][0]\n",
    "    len_x = tf.cast(len_x, tf.float32)\n",
    "    \n",
    "    sum_x = tf.reduce_sum(x, 0)   \n",
    "    sum_y = tf.reduce_sum(y, 0) \n",
    "    \n",
    "    sum_xy = tf.reduce_sum(tf.multiply(x,y))\n",
    "\n",
    "    sum_xx = tf.reduce_sum(tf.multiply(x,x))\n",
    "    sum_yy = tf.reduce_sum(tf.multiply(y,y))\n",
    "    \n",
    "    num = sum_xy-(tf.multiply(sum_x, sum_y) / len_x)\n",
    "    \n",
    "    den_x = (sum_xx)-(tf.multiply(sum_x, sum_x)/len_x)\n",
    "    den_y = (sum_yy)-(tf.multiply(sum_y, sum_y)/len_x)\n",
    "    den = tf.multiply(den_x, den_y)\n",
    "    den = tf.sqrt(den)\n",
    "    \n",
    "    ccf = tf.divide(num, den)\n",
    "    return ccf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def CCF_tf(latent_data, batch_size_feed):\n",
    "    latent_data = tf.reshape(latent_data, (batch_size_feed*timestep, dim_z))\n",
    "    \n",
    "    unit_ccf = tf.Variable([])\n",
    "    \n",
    "    for i in range(0, dim_z):\n",
    "        for j in range(dim_z-1, i, -1):\n",
    "            x = latent_data[:, i]\n",
    "            x = tf.cast(x, tf.float32)\n",
    "            y = latent_data[:, j]\n",
    "            y = tf.cast(y, tf.float32)\n",
    "            temp = CCF_tf_two(x,y)\n",
    "            temp = tf.abs(temp, name=None) \n",
    "            unit_ccf = tf.concat([unit_ccf, [temp]], 0)\n",
    "          \n",
    "    sum_ccf = tf.reduce_sum(unit_ccf) \n",
    "    max_ccf = tf.reduce_max(unit_ccf)\n",
    "    return sum_ccf, unit_ccf, max_ccf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-12-31f36a5d336d>:7: dense (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use keras.layers.dense instead.\n",
      "WARNING:tensorflow:From C:\\Users\\user\\Anaconda3\\envs\\tf_gpu_1.14\\lib\\site-packages\\tensorflow\\python\\ops\\init_ops.py:1251: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x0000024263EA0248>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x0000024263EA0248>>: AttributeError: module 'gast' has no attribute 'Index'\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x0000024263EA0248>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x0000024263EA0248>>: AttributeError: module 'gast' has no attribute 'Index'\n",
      "WARNING:tensorflow:From <ipython-input-12-31f36a5d336d>:8: dropout (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use keras.layers.dropout instead.\n",
      "WARNING:tensorflow:Entity <bound method Dropout.call of <tensorflow.python.layers.core.Dropout object at 0x0000024263DE9E08>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dropout.call of <tensorflow.python.layers.core.Dropout object at 0x0000024263DE9E08>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dropout.call of <tensorflow.python.layers.core.Dropout object at 0x0000024263DE9E08>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dropout.call of <tensorflow.python.layers.core.Dropout object at 0x0000024263DE9E08>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x0000024263DEA288>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x0000024263DEA288>>: AttributeError: module 'gast' has no attribute 'Index'\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x0000024263DEA288>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x0000024263DEA288>>: AttributeError: module 'gast' has no attribute 'Index'\n",
      "WARNING:tensorflow:Entity <bound method Dropout.call of <tensorflow.python.layers.core.Dropout object at 0x0000024263DBB548>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dropout.call of <tensorflow.python.layers.core.Dropout object at 0x0000024263DBB548>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dropout.call of <tensorflow.python.layers.core.Dropout object at 0x0000024263DBB548>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dropout.call of <tensorflow.python.layers.core.Dropout object at 0x0000024263DBB548>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x0000024263DBB548>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x0000024263DBB548>>: AttributeError: module 'gast' has no attribute 'Index'\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x0000024263DBB548>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x0000024263DBB548>>: AttributeError: module 'gast' has no attribute 'Index'\n",
      "WARNING:tensorflow:Entity <bound method Dropout.call of <tensorflow.python.layers.core.Dropout object at 0x000002425D9E9048>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dropout.call of <tensorflow.python.layers.core.Dropout object at 0x000002425D9E9048>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dropout.call of <tensorflow.python.layers.core.Dropout object at 0x000002425D9E9048>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dropout.call of <tensorflow.python.layers.core.Dropout object at 0x000002425D9E9048>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000002425D9E9048>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000002425D9E9048>>: AttributeError: module 'gast' has no attribute 'Index'\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000002425D9E9048>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000002425D9E9048>>: AttributeError: module 'gast' has no attribute 'Index'\n",
      "WARNING:tensorflow:Entity <bound method Dropout.call of <tensorflow.python.layers.core.Dropout object at 0x0000024263E22748>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dropout.call of <tensorflow.python.layers.core.Dropout object at 0x0000024263E22748>>: AssertionError: Bad argument number for Name: 3, expecting 4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: Entity <bound method Dropout.call of <tensorflow.python.layers.core.Dropout object at 0x0000024263E22748>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dropout.call of <tensorflow.python.layers.core.Dropout object at 0x0000024263E22748>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000002425D9E5808>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000002425D9E5808>>: AttributeError: module 'gast' has no attribute 'Index'\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000002425D9E5808>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000002425D9E5808>>: AttributeError: module 'gast' has no attribute 'Index'\n",
      "WARNING:tensorflow:Entity <bound method Dropout.call of <tensorflow.python.layers.core.Dropout object at 0x00000242642B4B88>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dropout.call of <tensorflow.python.layers.core.Dropout object at 0x00000242642B4B88>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dropout.call of <tensorflow.python.layers.core.Dropout object at 0x00000242642B4B88>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dropout.call of <tensorflow.python.layers.core.Dropout object at 0x00000242642B4B88>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x00000242642B4B88>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x00000242642B4B88>>: AttributeError: module 'gast' has no attribute 'Index'\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x00000242642B4B88>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x00000242642B4B88>>: AttributeError: module 'gast' has no attribute 'Index'\n",
      "WARNING:tensorflow:Entity <bound method Dropout.call of <tensorflow.python.layers.core.Dropout object at 0x000002426427C848>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dropout.call of <tensorflow.python.layers.core.Dropout object at 0x000002426427C848>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dropout.call of <tensorflow.python.layers.core.Dropout object at 0x000002426427C848>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dropout.call of <tensorflow.python.layers.core.Dropout object at 0x000002426427C848>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000002426427C848>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000002426427C848>>: AttributeError: module 'gast' has no attribute 'Index'\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000002426427C848>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000002426427C848>>: AttributeError: module 'gast' has no attribute 'Index'\n",
      "WARNING:tensorflow:Entity <bound method Dropout.call of <tensorflow.python.layers.core.Dropout object at 0x000002426427C848>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dropout.call of <tensorflow.python.layers.core.Dropout object at 0x000002426427C848>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dropout.call of <tensorflow.python.layers.core.Dropout object at 0x000002426427C848>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dropout.call of <tensorflow.python.layers.core.Dropout object at 0x000002426427C848>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000002426427C848>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000002426427C848>>: AttributeError: module 'gast' has no attribute 'Index'\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000002426427C848>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000002426427C848>>: AttributeError: module 'gast' has no attribute 'Index'\n",
      "WARNING:tensorflow:Entity <bound method Dropout.call of <tensorflow.python.layers.core.Dropout object at 0x0000024263DFD488>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dropout.call of <tensorflow.python.layers.core.Dropout object at 0x0000024263DFD488>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dropout.call of <tensorflow.python.layers.core.Dropout object at 0x0000024263DFD488>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dropout.call of <tensorflow.python.layers.core.Dropout object at 0x0000024263DFD488>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:From C:\\Users\\user\\Anaconda3\\envs\\tf_gpu_1.14\\lib\\site-packages\\tensorflow\\python\\ops\\losses\\losses_impl.py:121: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
     ]
    }
   ],
   "source": [
    "lr = 0.0001\n",
    "decay_rate = 0.8\n",
    "decay_step = 400\n",
    "\n",
    "# MODEL\n",
    "real_data, latent_data, fake_data = VAE_BP(X, keep_prob_feed, batch_size_feed)\n",
    "\n",
    "Recon_error = tf.losses.mean_squared_error(real_data, fake_data)\n",
    "\n",
    "total_error = Recon_error \n",
    "\n",
    "learning_rate_decayed = lr*decay_rate**(global_step/decay_step)\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate_decayed).minimize(total_error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization start!\n",
      "[1/400] Total_Error: 0.999, loss_Recon: 0.999\n",
      "VALID loss_Recon: 1.225\n",
      "[2/400] Total_Error: 0.981, loss_Recon: 0.981\n",
      "VALID loss_Recon: 1.217\n",
      "[3/400] Total_Error: 0.966, loss_Recon: 0.966\n",
      "VALID loss_Recon: 1.203\n",
      "[4/400] Total_Error: 0.944, loss_Recon: 0.944\n",
      "VALID loss_Recon: 1.175\n",
      "[5/400] Total_Error: 0.906, loss_Recon: 0.906\n",
      "VALID loss_Recon: 1.119\n",
      "[6/400] Total_Error: 0.843, loss_Recon: 0.843\n",
      "VALID loss_Recon: 1.025\n",
      "[7/400] Total_Error: 0.757, loss_Recon: 0.757\n",
      "VALID loss_Recon: 0.934\n",
      "[8/400] Total_Error: 0.678, loss_Recon: 0.678\n",
      "VALID loss_Recon: 0.873\n",
      "[9/400] Total_Error: 0.610, loss_Recon: 0.610\n",
      "VALID loss_Recon: 0.819\n",
      "[10/400] Total_Error: 0.554, loss_Recon: 0.554\n",
      "VALID loss_Recon: 0.772\n",
      "[11/400] Total_Error: 0.509, loss_Recon: 0.509\n",
      "VALID loss_Recon: 0.738\n",
      "[12/400] Total_Error: 0.468, loss_Recon: 0.468\n",
      "VALID loss_Recon: 0.719\n",
      "[13/400] Total_Error: 0.436, loss_Recon: 0.436\n",
      "VALID loss_Recon: 0.708\n",
      "[14/400] Total_Error: 0.415, loss_Recon: 0.415\n",
      "VALID loss_Recon: 0.694\n",
      "[15/400] Total_Error: 0.402, loss_Recon: 0.402\n",
      "VALID loss_Recon: 0.684\n",
      "[16/400] Total_Error: 0.391, loss_Recon: 0.391\n",
      "VALID loss_Recon: 0.722\n",
      "[17/400] Total_Error: 0.401, loss_Recon: 0.401\n",
      "VALID loss_Recon: 0.724\n",
      "[18/400] Total_Error: 0.412, loss_Recon: 0.412\n",
      "VALID loss_Recon: 0.689\n",
      "[19/400] Total_Error: 0.386, loss_Recon: 0.386\n",
      "VALID loss_Recon: 0.662\n",
      "[20/400] Total_Error: 0.340, loss_Recon: 0.340\n",
      "VALID loss_Recon: 0.629\n",
      "[21/400] Total_Error: 0.325, loss_Recon: 0.325\n",
      "VALID loss_Recon: 0.624\n",
      "[22/400] Total_Error: 0.304, loss_Recon: 0.304\n",
      "VALID loss_Recon: 0.628\n",
      "[23/400] Total_Error: 0.290, loss_Recon: 0.290\n",
      "VALID loss_Recon: 0.610\n",
      "[24/400] Total_Error: 0.276, loss_Recon: 0.276\n",
      "VALID loss_Recon: 0.605\n",
      "[25/400] Total_Error: 0.266, loss_Recon: 0.266\n",
      "VALID loss_Recon: 0.585\n",
      "[26/400] Total_Error: 0.260, loss_Recon: 0.260\n",
      "VALID loss_Recon: 0.598\n",
      "[27/400] Total_Error: 0.246, loss_Recon: 0.246\n",
      "VALID loss_Recon: 0.609\n",
      "[28/400] Total_Error: 0.251, loss_Recon: 0.251\n",
      "VALID loss_Recon: 0.624\n",
      "[29/400] Total_Error: 0.262, loss_Recon: 0.262\n",
      "VALID loss_Recon: 0.601\n",
      "[30/400] Total_Error: 0.261, loss_Recon: 0.261\n",
      "VALID loss_Recon: 0.632\n",
      "[31/400] Total_Error: 0.249, loss_Recon: 0.249\n",
      "VALID loss_Recon: 0.616\n",
      "[32/400] Total_Error: 0.250, loss_Recon: 0.250\n",
      "VALID loss_Recon: 0.592\n",
      "[33/400] Total_Error: 0.238, loss_Recon: 0.238\n",
      "VALID loss_Recon: 0.587\n",
      "[34/400] Total_Error: 0.221, loss_Recon: 0.221\n",
      "VALID loss_Recon: 0.574\n",
      "[35/400] Total_Error: 0.215, loss_Recon: 0.215\n",
      "VALID loss_Recon: 0.583\n",
      "[36/400] Total_Error: 0.207, loss_Recon: 0.207\n",
      "VALID loss_Recon: 0.569\n",
      "[37/400] Total_Error: 0.200, loss_Recon: 0.200\n",
      "VALID loss_Recon: 0.562\n",
      "[38/400] Total_Error: 0.188, loss_Recon: 0.188\n",
      "VALID loss_Recon: 0.555\n",
      "[39/400] Total_Error: 0.180, loss_Recon: 0.180\n",
      "VALID loss_Recon: 0.556\n",
      "[40/400] Total_Error: 0.178, loss_Recon: 0.178\n",
      "VALID loss_Recon: 0.553\n",
      "[41/400] Total_Error: 0.171, loss_Recon: 0.171\n",
      "VALID loss_Recon: 0.547\n",
      "[42/400] Total_Error: 0.166, loss_Recon: 0.166\n",
      "VALID loss_Recon: 0.537\n",
      "[43/400] Total_Error: 0.156, loss_Recon: 0.156\n",
      "VALID loss_Recon: 0.542\n",
      "[44/400] Total_Error: 0.153, loss_Recon: 0.153\n",
      "VALID loss_Recon: 0.546\n",
      "[45/400] Total_Error: 0.156, loss_Recon: 0.156\n",
      "VALID loss_Recon: 0.550\n",
      "[46/400] Total_Error: 0.152, loss_Recon: 0.152\n",
      "VALID loss_Recon: 0.553\n",
      "[47/400] Total_Error: 0.148, loss_Recon: 0.148\n",
      "VALID loss_Recon: 0.551\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-16-1dfa067e468e>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     43\u001b[0m                                              \u001b[0mkeep_prob_feed\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mkeep_prob\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     44\u001b[0m                                              \u001b[0mglobal_step\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mepoch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 45\u001b[1;33m                                              \u001b[0mbatch_size_feed\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mbatch_size_train\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     46\u001b[0m                                             })     \n\u001b[0;32m     47\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tf_gpu_1.14\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m    948\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    949\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[1;32m--> 950\u001b[1;33m                          run_metadata_ptr)\n\u001b[0m\u001b[0;32m    951\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    952\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tf_gpu_1.14\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run\u001b[1;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1171\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[1;32mor\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1172\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[1;32m-> 1173\u001b[1;33m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[0;32m   1174\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1175\u001b[0m       \u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tf_gpu_1.14\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_run\u001b[1;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1348\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1349\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[1;32m-> 1350\u001b[1;33m                            run_metadata)\n\u001b[0m\u001b[0;32m   1351\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1352\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tf_gpu_1.14\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_call\u001b[1;34m(self, fn, *args)\u001b[0m\n\u001b[0;32m   1354\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1355\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1356\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1357\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1358\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tf_gpu_1.14\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[1;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[0;32m   1339\u001b[0m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_extend_graph\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1340\u001b[0m       return self._call_tf_sessionrun(\n\u001b[1;32m-> 1341\u001b[1;33m           options, feed_dict, fetch_list, target_list, run_metadata)\n\u001b[0m\u001b[0;32m   1342\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1343\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tf_gpu_1.14\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_call_tf_sessionrun\u001b[1;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[0;32m   1427\u001b[0m     return tf_session.TF_SessionRun_wrapper(\n\u001b[0;32m   1428\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1429\u001b[1;33m         run_metadata)\n\u001b[0m\u001b[0;32m   1430\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1431\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_call_tf_sessionprun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "train_epoch = 400  #300\n",
    "keep_prob = 0.0001\n",
    "batch_size_train = batch_size\n",
    "\n",
    "# save loss\n",
    "train_hist = {}\n",
    "train_hist['Recon_e_list'] = []\n",
    "train_hist['Total_Error_list'] = []\n",
    "train_hist['sum_CCF'] = []\n",
    "\n",
    "valid_hist = {}\n",
    "valid_hist['Recon_e_list_valid'] = []\n",
    "\n",
    "saver = tf.train.Saver()\n",
    "\n",
    "session_config = tf.ConfigProto(gpu_options = tf.GPUOptions(allow_growth=True))\n",
    "with tf.Session(config = session_config) as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "\n",
    "    print('Optimization start!')\n",
    "    start = time.time()\n",
    "    \n",
    "    for epoch in range(train_epoch):\n",
    "        Recon_e_list = []\n",
    "        Total_Error_list = []\n",
    "        ori_data = []\n",
    "        gen_data = []\n",
    "        sum_CCF = []\n",
    "        \n",
    "        for i in range(len(tep_data_win) // batch_size): # 250/5\n",
    "            real_data = tep_data_win[i * batch_size: (i + 1) * batch_size]     #(batch_size)\n",
    "            real_data = real_data.reshape((batch_size, timestep, dim_input))\n",
    "\n",
    "            _, total_error_, Recon_e = sess.run([optimizer, total_error, Recon_error], \n",
    "                                                    feed_dict = {X: real_data, \n",
    "                                                                 keep_prob_feed: keep_prob,\n",
    "                                                                 global_step: epoch,\n",
    "                                                                 batch_size_feed: batch_size_train\n",
    "                                                                })\n",
    "            \n",
    "            generated_output = sess.run([fake_data, ], \n",
    "                                feed_dict = {X: real_data, \n",
    "                                             keep_prob_feed: keep_prob,\n",
    "                                             global_step: epoch,\n",
    "                                             batch_size_feed: batch_size_train\n",
    "                                            })     \n",
    "            \n",
    "            Recon_e_list.append(Recon_e)\n",
    "            Total_Error_list.append(total_error_)\n",
    "            ori_data.append(real_data)   \n",
    "            gen_data.append(generated_output)  \n",
    "            \n",
    "\n",
    "        ''' valid '''\n",
    "        ori_data_test2 = []\n",
    "        gen_data_test2 = []    \n",
    "        batch_size_test2 = len(tep_data_test)\n",
    "\n",
    "        real_data = tep_data_test\n",
    "        real_data = real_data.reshape((-1, timestep, dim_input))\n",
    "\n",
    "        generated_output_test2, Recon_error_valid = sess.run([fake_data, Recon_error], \n",
    "                            feed_dict = {X: real_data, \n",
    "                                         keep_prob_feed: 1,\n",
    "                                         global_step: epoch,\n",
    "                                         batch_size_feed: batch_size_test2\n",
    "                                        })    \n",
    "\n",
    "        ori_data_test2.append( real_data.reshape((-1, dim_input)) )\n",
    "        gen_data_test2.append( np.array(generated_output_test2).reshape((-1, dim_input))) \n",
    "        valid_hist['Recon_e_list_valid'].append(Recon_error_valid)  \n",
    "        \n",
    "    ############        show result      #######################\n",
    "        if (epoch+1) % 1 == 0:\n",
    "            print('[%d/%d] Total_Error: %.3f, loss_Recon: %.3f'%((epoch + 1), train_epoch,\n",
    "                                                np.mean(Total_Error_list), np.mean(Recon_e_list)))\n",
    "            \n",
    "            print('VALID loss_Recon: %.3f'%(Recon_error_valid))\n",
    "        train_hist['Recon_e_list'].append(np.mean(Recon_e_list))  \n",
    "        train_hist['Total_Error_list'].append(np.mean(Total_Error_list))  \n",
    "\n",
    "    #############        save model      #######################\n",
    "    saver.save(sess, saver_path)   \n",
    "    sess.close()\n",
    "    \n",
    "    \n",
    "print(\"Optimization Finished!\")\n",
    "end = time.time()\n",
    "print(\"runtime%f \" % (end - start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(0)  \n",
    "plt.plot(train_hist['Recon_e_list'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(valid_hist['Recon_e_list_valid'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ori_data = np.array(ori_data).reshape((-1, dim_input))\n",
    "gen_data = np.array(gen_data).reshape((-1, dim_input))\n",
    "\n",
    "ori_data = (ori_data*data_std) + data_mean\n",
    "gen_data = (gen_data*data_std) + data_mean\n",
    "\n",
    "print(ori_data.shape)\n",
    "print(gen_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(tep_data.shape[1]):\n",
    "    plt.figure(i)  \n",
    "    plt.title(i)\n",
    "    plt.plot(ori_data[:,i],'r')\n",
    "    plt.plot(gen_data[:,i])\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
